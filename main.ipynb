{"cells":[{"cell_type":"markdown","id":"e64d63b4","metadata":{"id":"e64d63b4"},"source":["# Data Collection"]},{"cell_type":"code","execution_count":1,"id":"0c2fad78","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0c2fad78","executionInfo":{"status":"ok","timestamp":1759589550496,"user_tz":-360,"elapsed":8198,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"75e7a22b-8884-4deb-b7ab-d35252c655d8"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package gutenberg to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/gutenberg.zip.\n"]}],"source":["# Step 1: Import necessary libraries\n","import nltk\n","import pandas as pd\n","\n","# Step 2: Download the Gutenberg corpus from NLTK\n","nltk.download('gutenberg')\n","\n","# Step 3: Import the Gutenberg corpus\n","from nltk.corpus import gutenberg\n","\n","# Step 4: Load the 'Hamlet' text\n","data = gutenberg.raw('shakespeare-hamlet.txt')  # This loads the raw text of Hamlet\n","\n","# Step 5: Save the loaded text into a local file\n","with open('hamlet.txt', 'w') as file:\n","    file.write(data)  # Write the full text into 'hamlet.txt' file\n"]},{"cell_type":"markdown","metadata":{"id":"3c12aa77"},"source":["Now that you have trained and saved your model and tokenizer, you can download them to your local machine for deployment. The following code will create a zip file containing the necessary files."],"id":"3c12aa77"},{"cell_type":"markdown","metadata":{"id":"447a978d"},"source":["You can now download the `next_word_prediction_model.zip` file from the Colab file explorer (the folder icon on the left sidebar)."],"id":"447a978d"},{"cell_type":"markdown","id":"42ceaf56","metadata":{"id":"42ceaf56"},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":2,"id":"64004481","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"64004481","executionInfo":{"status":"ok","timestamp":1759589556243,"user_tz":-360,"elapsed":5735,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"1cd3de5f-86ca-4775-873b-b9b1e1dfac04"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total unique words: 4818\n"]}],"source":["# Step 1: Import necessary libraries\n","import numpy as np\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","# Step 2: Load the dataset\n","with open('hamlet.txt', 'r') as file:\n","    text = file.read().lower()  # Read the text file and convert all text to lowercase\n","\n","# Step 3: Initialize the Tokenizer\n","tokenizer = Tokenizer()  # This will convert words into unique integer indices\n","\n","# Step 4: Fit the tokenizer on the text\n","tokenizer.fit_on_texts([text])  # Learn the vocabulary from the text\n","\n","# Step 5: Get total number of unique words\n","total_words = len(tokenizer.word_index) + 1  # +1 because index starts from 1\n","print(f'Total unique words: {total_words}')\n"]},{"cell_type":"code","execution_count":3,"id":"e9f96e2b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e9f96e2b","executionInfo":{"status":"ok","timestamp":1759589556402,"user_tz":-360,"elapsed":144,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"446fab0a-1315-43e7-f8a4-6acab7f1c8bb","collapsed":true},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'the': 1,\n"," 'and': 2,\n"," 'to': 3,\n"," 'of': 4,\n"," 'i': 5,\n"," 'you': 6,\n"," 'a': 7,\n"," 'my': 8,\n"," 'it': 9,\n"," 'in': 10,\n"," 'that': 11,\n"," 'ham': 12,\n"," 'is': 13,\n"," 'not': 14,\n"," 'his': 15,\n"," 'this': 16,\n"," 'with': 17,\n"," 'your': 18,\n"," 'but': 19,\n"," 'for': 20,\n"," 'me': 21,\n"," 'lord': 22,\n"," 'as': 23,\n"," 'what': 24,\n"," 'he': 25,\n"," 'be': 26,\n"," 'so': 27,\n"," 'him': 28,\n"," 'haue': 29,\n"," 'king': 30,\n"," 'will': 31,\n"," 'no': 32,\n"," 'our': 33,\n"," 'we': 34,\n"," 'on': 35,\n"," 'are': 36,\n"," 'if': 37,\n"," 'all': 38,\n"," 'then': 39,\n"," 'shall': 40,\n"," 'by': 41,\n"," 'thou': 42,\n"," 'come': 43,\n"," 'or': 44,\n"," 'hamlet': 45,\n"," 'good': 46,\n"," 'do': 47,\n"," 'hor': 48,\n"," 'her': 49,\n"," 'let': 50,\n"," 'now': 51,\n"," 'thy': 52,\n"," 'how': 53,\n"," 'more': 54,\n"," 'they': 55,\n"," 'from': 56,\n"," 'enter': 57,\n"," 'at': 58,\n"," 'was': 59,\n"," 'oh': 60,\n"," 'like': 61,\n"," 'most': 62,\n"," 'there': 63,\n"," 'well': 64,\n"," 'know': 65,\n"," 'selfe': 66,\n"," 'would': 67,\n"," 'them': 68,\n"," 'loue': 69,\n"," 'may': 70,\n"," \"'tis\": 71,\n"," 'vs': 72,\n"," 'sir': 73,\n"," 'qu': 74,\n"," 'which': 75,\n"," 'did': 76,\n"," 'why': 77,\n"," 'laer': 78,\n"," 'giue': 79,\n"," 'thee': 80,\n"," 'ile': 81,\n"," 'must': 82,\n"," 'hath': 83,\n"," 'ophe': 84,\n"," 'speake': 85,\n"," 'out': 86,\n"," 'make': 87,\n"," 'should': 88,\n"," 'where': 89,\n"," 'too': 90,\n"," 'an': 91,\n"," 'am': 92,\n"," 'such': 93,\n"," 'say': 94,\n"," 'when': 95,\n"," 'vpon': 96,\n"," 'father': 97,\n"," 'doe': 98,\n"," 'very': 99,\n"," 'pol': 100,\n"," 'go': 101,\n"," 'their': 102,\n"," 'one': 103,\n"," 'man': 104,\n"," 'see': 105,\n"," 'some': 106,\n"," 'heere': 107,\n"," 'had': 108,\n"," 'heauen': 109,\n"," 'time': 110,\n"," 'mine': 111,\n"," 'these': 112,\n"," 'she': 113,\n"," 'much': 114,\n"," 'tell': 115,\n"," 'rosin': 116,\n"," 'thinke': 117,\n"," 'play': 118,\n"," 'thus': 119,\n"," 'horatio': 120,\n"," 'who': 121,\n"," 'mother': 122,\n"," 'queene': 123,\n"," 'night': 124,\n"," 'o': 125,\n"," 'polon': 126,\n"," 'yet': 127,\n"," 'vp': 128,\n"," 'death': 129,\n"," 'laertes': 130,\n"," 'againe': 131,\n"," 'can': 132,\n"," 'both': 133,\n"," \"th'\": 134,\n"," 'soule': 135,\n"," 'take': 136,\n"," 'life': 137,\n"," 'nor': 138,\n"," 'heare': 139,\n"," 'mar': 140,\n"," 'looke': 141,\n"," 'owne': 142,\n"," 'could': 143,\n"," 'heart': 144,\n"," 'dead': 145,\n"," 'might': 146,\n"," 'made': 147,\n"," 'clo': 148,\n"," 'hast': 149,\n"," 'downe': 150,\n"," 'pray': 151,\n"," 'ophelia': 152,\n"," 'nothing': 153,\n"," 'away': 154,\n"," 'whose': 155,\n"," 'doth': 156,\n"," 'other': 157,\n"," 'cannot': 158,\n"," 'leaue': 159,\n"," 'indeed': 160,\n"," 'into': 161,\n"," 'nay': 162,\n"," 'god': 163,\n"," 'head': 164,\n"," 'were': 165,\n"," 'matter': 166,\n"," 'thing': 167,\n"," 'hold': 168,\n"," 'day': 169,\n"," 'world': 170,\n"," 'nature': 171,\n"," 'neuer': 172,\n"," 'comes': 173,\n"," 'done': 174,\n"," 'exeunt': 175,\n"," 'call': 176,\n"," 'two': 177,\n"," 'true': 178,\n"," 'though': 179,\n"," 'sweet': 180,\n"," 'put': 181,\n"," 'set': 182,\n"," 'ghost': 183,\n"," 'euen': 184,\n"," 'earth': 185,\n"," 'feare': 186,\n"," 'madnesse': 187,\n"," 'mad': 188,\n"," 'seene': 189,\n"," 'eyes': 190,\n"," 'against': 191,\n"," 'faire': 192,\n"," 'denmarke': 193,\n"," 'those': 194,\n"," \"o're\": 195,\n"," 'polonius': 196,\n"," 'deere': 197,\n"," 'fathers': 198,\n"," 'sonne': 199,\n"," 'poore': 200,\n"," 'himselfe': 201,\n"," 'follow': 202,\n"," 'guild': 203,\n"," 'england': 204,\n"," 'friends': 205,\n"," 'once': 206,\n"," 'hand': 207,\n"," 'shew': 208,\n"," 'about': 209,\n"," \"i'th'\": 210,\n"," 'off': 211,\n"," 'within': 212,\n"," 'till': 213,\n"," 'great': 214,\n"," 'meanes': 215,\n"," 'words': 216,\n"," 'players': 217,\n"," 'exit': 218,\n"," 'part': 219,\n"," 'still': 220,\n"," 'does': 221,\n"," 'hee': 222,\n"," 'osr': 223,\n"," 'long': 224,\n"," 'before': 225,\n"," 'beleeue': 226,\n"," 'any': 227,\n"," 'old': 228,\n"," 'thoughts': 229,\n"," 'first': 230,\n"," 'eare': 231,\n"," 'keepe': 232,\n"," 'goe': 233,\n"," 'end': 234,\n"," 'guildensterne': 235,\n"," 'welcome': 236,\n"," 'while': 237,\n"," 'art': 238,\n"," 'noble': 239,\n"," 'body': 240,\n"," 'bee': 241,\n"," 'daughter': 242,\n"," 'speech': 243,\n"," 'makes': 244,\n"," \"there's\": 245,\n"," 'sword': 246,\n"," 'stand': 247,\n"," 'liue': 248,\n"," \"that's\": 249,\n"," 'farewell': 250,\n"," 'kin': 251,\n"," 'ere': 252,\n"," 'marry': 253,\n"," 'betweene': 254,\n"," 'many': 255,\n"," 'since': 256,\n"," 'watch': 257,\n"," \"ha's\": 258,\n"," 'therefore': 259,\n"," 'question': 260,\n"," 'thought': 261,\n"," 'heard': 262,\n"," 'spirit': 263,\n"," 'eye': 264,\n"," 'better': 265,\n"," 'thine': 266,\n"," 'tongue': 267,\n"," 'drinke': 268,\n"," 'youth': 269,\n"," 'sent': 270,\n"," 'graue': 271,\n"," 'rest': 272,\n"," 'bed': 273,\n"," 'last': 274,\n"," 'same': 275,\n"," 'marke': 276,\n"," 'gone': 277,\n"," 'without': 278,\n"," 'state': 279,\n"," \"is't\": 280,\n"," 'goes': 281,\n"," 'fortinbras': 282,\n"," 'vse': 283,\n"," 'grace': 284,\n"," 'euer': 285,\n"," 'finde': 286,\n"," 'gertrude': 287,\n"," 'beare': 288,\n"," 'little': 289,\n"," 'breath': 290,\n"," \"wee'l\": 291,\n"," 'saw': 292,\n"," 'beene': 293,\n"," 'none': 294,\n"," 'vertue': 295,\n"," 'else': 296,\n"," 'said': 297,\n"," 'after': 298,\n"," 'reynol': 299,\n"," 'cause': 300,\n"," 'forme': 301,\n"," 'something': 302,\n"," 'ayre': 303,\n"," 'farre': 304,\n"," 'selues': 305,\n"," 'purpose': 306,\n"," 'further': 307,\n"," 'reason': 308,\n"," 'friend': 309,\n"," 'madam': 310,\n"," 'remember': 311,\n"," 'faith': 312,\n"," 'gentlemen': 313,\n"," 'word': 314,\n"," 'foule': 315,\n"," 'winde': 316,\n"," 'meane': 317,\n"," 'bring': 318,\n"," 'fit': 319,\n"," 'blood': 320,\n"," 'helpe': 321,\n"," 'honest': 322,\n"," 'stay': 323,\n"," \"in't\": 324,\n"," 'being': 325,\n"," 'fire': 326,\n"," 'things': 327,\n"," \"what's\": 328,\n"," 'newes': 329,\n"," 'best': 330,\n"," 'kinde': 331,\n"," 'excellent': 332,\n"," 'each': 333,\n"," 'sleepe': 334,\n"," 'way': 335,\n"," 'please': 336,\n"," 'free': 337,\n"," 'reuenge': 338,\n"," 'villaine': 339,\n"," 'right': 340,\n"," 'ha': 341,\n"," 'passion': 342,\n"," 'rosincrance': 343,\n"," 'dost': 344,\n"," 'verie': 345,\n"," 'barn': 346,\n"," 'marcellus': 347,\n"," 'men': 348,\n"," 'peace': 349,\n"," 'together': 350,\n"," 'full': 351,\n"," 'voyce': 352,\n"," 'oft': 353,\n"," 'greefe': 354,\n"," \"'twere\": 355,\n"," 'late': 356,\n"," 'businesse': 357,\n"," 'doubt': 358,\n"," 'alone': 359,\n"," 'minde': 360,\n"," 'heauens': 361,\n"," 'face': 362,\n"," 'hell': 363,\n"," 'ye': 364,\n"," 'second': 365,\n"," 'iudgement': 366,\n"," 'giuen': 367,\n"," 'command': 368,\n"," 'action': 369,\n"," \"let's\": 370,\n"," 'murther': 371,\n"," 'guil': 372,\n"," 'lady': 373,\n"," 'fortune': 374,\n"," 'mee': 375,\n"," 'pyrrhus': 376,\n"," 'answer': 377,\n"," 'get': 378,\n"," 'thankes': 379,\n"," 'goodnight': 380,\n"," 'eares': 381,\n"," 'breake': 382,\n"," 'hora': 383,\n"," 'strange': 384,\n"," 'young': 385,\n"," 'walke': 386,\n"," 'brothers': 387,\n"," 'seeme': 388,\n"," 'name': 389,\n"," 'fellow': 390,\n"," 'act': 391,\n"," 'hands': 392,\n"," 'armes': 393,\n"," 'deare': 394,\n"," 'neere': 395,\n"," 'phrase': 396,\n"," 'draw': 397,\n"," 'gho': 398,\n"," 'alas': 399,\n"," 'ought': 400,\n"," 'offence': 401,\n"," 'sweare': 402,\n"," 'worke': 403,\n"," 'gentleman': 404,\n"," 'fine': 405,\n"," 'three': 406,\n"," 'barnardo': 407,\n"," 'fran': 408,\n"," 'ground': 409,\n"," 'sight': 410,\n"," 'sit': 411,\n"," 'maiesty': 412,\n"," 'pale': 413,\n"," \"on't\": 414,\n"," 'fell': 415,\n"," 'lost': 416,\n"," 'soft': 417,\n"," 'power': 418,\n"," 'yong': 419,\n"," 'duty': 420,\n"," 'whole': 421,\n"," 'woe': 422,\n"," 'ioy': 423,\n"," 'wife': 424,\n"," 'came': 425,\n"," 'queen': 426,\n"," 'seeke': 427,\n"," 'common': 428,\n"," 'seemes': 429,\n"," 'blacke': 430,\n"," 'kings': 431,\n"," 'teares': 432,\n"," 'top': 433,\n"," 'fashion': 434,\n"," 'deed': 435,\n"," 'euery': 436,\n"," 'light': 437,\n"," 'custome': 438,\n"," 'borne': 439,\n"," 'wilt': 440,\n"," 'hither': 441,\n"," 'lay': 442,\n"," 'another': 443,\n"," 'ouer': 444,\n"," 'age': 445,\n"," 'thousand': 446,\n"," 'fall': 447,\n"," 'lye': 448,\n"," 'conscience': 449,\n"," 'husband': 450,\n"," 'bar': 451,\n"," 'lookes': 452,\n"," 'charge': 453,\n"," 'knowne': 454,\n"," 'law': 455,\n"," 'bin': 456,\n"," 'sound': 457,\n"," 'sister': 458,\n"," 'memory': 459,\n"," 'brother': 460,\n"," 'beseech': 461,\n"," 'lesse': 462,\n"," 'dust': 463,\n"," 'through': 464,\n"," 'shewes': 465,\n"," 'desire': 466,\n"," 'obey': 467,\n"," 'woman': 468,\n"," 'almost': 469,\n"," 'grow': 470,\n"," 'here': 471,\n"," 'shame': 472,\n"," 'giues': 473,\n"," \"too't\": 474,\n"," 'takes': 475,\n"," 'table': 476,\n"," 'sure': 477,\n"," 'musicke': 478,\n"," 'letters': 479,\n"," 'hamlets': 480,\n"," 'hope': 481,\n"," 'receiue': 482,\n"," 'maiestie': 483,\n"," 'thanke': 484,\n"," 'gaue': 485,\n"," 'bad': 486,\n"," 'wee': 487,\n"," 'ore': 488,\n"," 'noise': 489,\n"," 'times': 490,\n"," 'cold': 491,\n"," 'bid': 492,\n"," 'dane': 493,\n"," 'place': 494,\n"," 'peece': 495,\n"," 'buried': 496,\n"," 'cast': 497,\n"," 'hot': 498,\n"," 'list': 499,\n"," 'wrong': 500,\n"," 'sea': 501,\n"," 'truth': 502,\n"," 'sayes': 503,\n"," 'season': 504,\n"," 'gracious': 505,\n"," 'dumbe': 506,\n"," 'loues': 507,\n"," 'sorrow': 508,\n"," 'marriage': 509,\n"," 'writ': 510,\n"," 'mouth': 511,\n"," 'pardon': 512,\n"," 'note': 513,\n"," 'backe': 514,\n"," 'lordship': 515,\n"," 'mothers': 516,\n"," 'beard': 517,\n"," 'fare': 518,\n"," 'seruice': 519,\n"," 'withall': 520,\n"," 'maid': 521,\n"," 'enough': 522,\n"," 'effect': 523,\n"," 'double': 524,\n"," 'neither': 525,\n"," 'false': 526,\n"," 'vnderstand': 527,\n"," 'circumstance': 528,\n"," 'foole': 529,\n"," 'vowes': 530,\n"," 'keepes': 531,\n"," 'shape': 532,\n"," 'dayes': 533,\n"," 'fat': 534,\n"," 'crowne': 535,\n"," 'wits': 536,\n"," 'damned': 537,\n"," 'ho': 538,\n"," 'needs': 539,\n"," 'touch': 540,\n"," 'ranke': 541,\n"," 'generall': 542,\n"," 'moue': 543,\n"," 'home': 544,\n"," 'ill': 545,\n"," 'round': 546,\n"," 'fortunes': 547,\n"," 'laugh': 548,\n"," 'yours': 549,\n"," \"he's\": 550,\n"," 'honor': 551,\n"," 'begin': 552,\n"," 'anon': 553,\n"," 'proofe': 554,\n"," 'gods': 555,\n"," 'quicke': 556,\n"," 'dangerous': 557,\n"," 'christian': 558,\n"," 'danish': 559,\n"," 'poyson': 560,\n"," 'begge': 561,\n"," 'wager': 562,\n"," \"drown'd\": 563,\n"," 'water': 564,\n"," 'scull': 565,\n"," 'houre': 566,\n"," 'twelue': 567,\n"," 'quiet': 568,\n"," 'course': 569,\n"," 'sometimes': 570,\n"," 'march': 571,\n"," 'look': 572,\n"," 'norwey': 573,\n"," 'particular': 574,\n"," 'land': 575,\n"," \"do's\": 576,\n"," 'vnto': 577,\n"," 'speak': 578,\n"," 'spirits': 579,\n"," 'cocke': 580,\n"," 'guilty': 581,\n"," \"'gainst\": 582,\n"," 'wholsome': 583,\n"," 'lords': 584,\n"," 'kingdome': 585,\n"," 'freely': 586,\n"," 'dreame': 587,\n"," 'told': 588,\n"," 'loose': 589,\n"," 'dread': 590,\n"," 'returne': 591,\n"," 'france': 592,\n"," 'confesse': 593,\n"," 'dye': 594,\n"," 'visage': 595,\n"," 'truly': 596,\n"," 'bound': 597,\n"," 'prythee': 598,\n"," 'health': 599,\n"," 'flesh': 600,\n"," 'fie': 601,\n"," 'beast': 602,\n"," 'discourse': 603,\n"," 'longer': 604,\n"," 'wicked': 605,\n"," 'disposition': 606,\n"," 'report': 607,\n"," 'teach': 608,\n"," 'forth': 609,\n"," 'thinkes': 610,\n"," 'tis': 611,\n"," 'yes': 612,\n"," 'countenance': 613,\n"," 'perchance': 614,\n"," 'warrant': 615,\n"," 'silence': 616,\n"," 'perhaps': 617,\n"," 'wisedome': 618,\n"," 'blessing': 619,\n"," 'dull': 620,\n"," 'mans': 621,\n"," 'audience': 622,\n"," \"you'l\": 623,\n"," 'making': 624,\n"," \"damn'd\": 625,\n"," 'soules': 626,\n"," 'cries': 627,\n"," 'desperate': 628,\n"," 'shalt': 629,\n"," 'prison': 630,\n"," 'went': 631,\n"," 'naturall': 632,\n"," 'holds': 633,\n"," 'sodaine': 634,\n"," 'adue': 635,\n"," 'braine': 636,\n"," 'knaue': 637,\n"," 'point': 638,\n"," 'vnder': 639,\n"," 'mercy': 640,\n"," 'lacke': 641,\n"," \"heere's\": 642,\n"," \"in's\": 643,\n"," 'tooke': 644,\n"," 'arme': 645,\n"," 'brought': 646,\n"," 'dutie': 647,\n"," 'found': 648,\n"," 'whereon': 649,\n"," 'commission': 650,\n"," 'passe': 651,\n"," 'vilde': 652,\n"," 'short': 653,\n"," 'try': 654,\n"," 'behinde': 655,\n"," 'presently': 656,\n"," 'slaue': 657,\n"," 'saue': 658,\n"," 'ambition': 659,\n"," 'sing': 660,\n"," 'themselues': 661,\n"," 'braines': 662,\n"," \"'twas\": 663,\n"," 'onely': 664,\n"," 'french': 665,\n"," 'treason': 666,\n"," 'morrow': 667,\n"," 'conceit': 668,\n"," 'drowne': 669,\n"," 'fellowes': 670,\n"," 'hoa': 671,\n"," 'patience': 672,\n"," 'halfe': 673,\n"," 'yeare': 674,\n"," 'forgot': 675,\n"," 'hence': 676,\n"," \"doo't\": 677,\n"," \"e'ene\": 678,\n"," 'slaine': 679,\n"," 'sense': 680,\n"," 'buriall': 681,\n"," 'alexander': 682,\n"," 'osricke': 683,\n"," 'carriages': 684,\n"," 'foyles': 685,\n"," 'hit': 686,\n"," 'tragedie': 687,\n"," 'sicke': 688,\n"," 'meet': 689,\n"," 'twice': 690,\n"," \"'twill\": 691,\n"," 'nights': 692,\n"," 'starre': 693,\n"," \"t'\": 694,\n"," 'figure': 695,\n"," 'wonder': 696,\n"," 'warlike': 697,\n"," 'cannon': 698,\n"," 'toward': 699,\n"," 'image': 700,\n"," 'norway': 701,\n"," \"seal'd\": 702,\n"," 'lands': 703,\n"," 'stood': 704,\n"," \"return'd\": 705,\n"," 'strong': 706,\n"," 'motiue': 707,\n"," 'ease': 708,\n"," 'treasure': 709,\n"," 'stop': 710,\n"," 'violence': 711,\n"," 'trumpet': 712,\n"," 'whether': 713,\n"," 'heerein': 714,\n"," 'wherein': 715,\n"," 'impart': 716,\n"," 'morning': 717,\n"," 'attendant': 718,\n"," 'brow': 719,\n"," 'discretion': 720,\n"," 'followes': 721,\n"," 'frame': 722,\n"," 'cornelius': 723,\n"," 'giuing': 724,\n"," 'commend': 725,\n"," \"would'st\": 726,\n"," 'natiue': 727,\n"," 'fauour': 728,\n"," 'hang': 729,\n"," 'colour': 730,\n"," 'show': 731,\n"," 'fault': 732,\n"," 'throw': 733,\n"," 'lose': 734,\n"," 'gentle': 735,\n"," 'sits': 736,\n"," 'growes': 737,\n"," 'visit': 738,\n"," 'growne': 739,\n"," 'vnkle': 740,\n"," 'left': 741,\n"," 'speed': 742,\n"," 'incestuous': 743,\n"," 'glad': 744,\n"," 'forget': 745,\n"," 'thrift': 746,\n"," \"arm'd\": 747,\n"," 'thrice': 748,\n"," 'length': 749,\n"," 'kept': 750,\n"," 'knew': 751,\n"," 'answere': 752,\n"," 'honour': 753,\n"," 'wide': 754,\n"," 'force': 755,\n"," 'affection': 756,\n"," 'shot': 757,\n"," 'danger': 758,\n"," 'moone': 759,\n"," 'safety': 760,\n"," 'lies': 761,\n"," 'buy': 762,\n"," 'aboue': 763,\n"," 'humbly': 764,\n"," 'tend': 765,\n"," 'ist': 766,\n"," 'bloud': 767,\n"," 'heate': 768,\n"," 'bones': 769,\n"," 'base': 770,\n"," 'horrible': 771,\n"," 'imagination': 772,\n"," 'direct': 773,\n"," 'lend': 774,\n"," 'hearing': 775,\n"," 'certaine': 776,\n"," 'fast': 777,\n"," 'house': 778,\n"," 'tale': 779,\n"," 'start': 780,\n"," 'vnnaturall': 781,\n"," \"it's\": 782,\n"," 'sleeping': 783,\n"," 'wit': 784,\n"," 'gifts': 785,\n"," 'seeming': 786,\n"," 'wil': 787,\n"," 'court': 788,\n"," 'cursed': 789,\n"," 'instant': 790,\n"," 'bosome': 791,\n"," 'distracted': 792,\n"," 'yea': 793,\n"," 'past': 794,\n"," 'booke': 795,\n"," 'think': 796,\n"," 'secret': 797,\n"," 'already': 798,\n"," 'stage': 799,\n"," 'seeing': 800,\n"," 'fingers': 801,\n"," 'reynoldo': 802,\n"," 'drift': 803,\n"," 'liberty': 804,\n"," 'closes': 805,\n"," 'consequence': 806,\n"," 'chamber': 807,\n"," \"turn'd\": 808,\n"," 'extasie': 809,\n"," 'violent': 810,\n"," 'meant': 811,\n"," 'hide': 812,\n"," 'whom': 813,\n"," 'rather': 814,\n"," 'white': 815,\n"," 'awhile': 816,\n"," 'idle': 817,\n"," 'thence': 818,\n"," 'bene': 819,\n"," 'foure': 820,\n"," 'honestie': 821,\n"," 'either': 822,\n"," 'count': 823,\n"," 'dreames': 824,\n"," 'bodies': 825,\n"," 'comming': 826,\n"," 'shal': 827,\n"," 'player': 828,\n"," 'flourish': 829,\n"," 'asse': 830,\n"," 'heauy': 831,\n"," 'masters': 832,\n"," '1': 833,\n"," 'others': 834,\n"," 'modestie': 835,\n"," 'cunning': 836,\n"," \"lou'd\": 837,\n"," 'horse': 838,\n"," 'priam': 839,\n"," 'new': 840,\n"," 'sleepes': 841,\n"," 'hecuba': 842,\n"," 'mortall': 843,\n"," 'weepe': 844,\n"," 'pate': 845,\n"," 'diuell': 846,\n"," 'blame': 847,\n"," 'flye': 848,\n"," 'turne': 849,\n"," 'beautie': 850,\n"," 'acte': 851,\n"," 'nunnery': 852,\n"," 'snow': 853,\n"," 'rose': 854,\n"," 'quite': 855,\n"," 'ladies': 856,\n"," 'wretched': 857,\n"," 'send': 858,\n"," 'weare': 859,\n"," \"kill'd\": 860,\n"," 'kill': 861,\n"," 'maker': 862,\n"," 'prologue': 863,\n"," 'shortly': 864,\n"," 'begun': 865,\n"," 'lights': 866,\n"," 'heeles': 867,\n"," 'doore': 868,\n"," 'meete': 869,\n"," 'stronger': 870,\n"," 'whereto': 871,\n"," 'next': 872,\n"," 'messenger': 873,\n"," 'choose': 874,\n"," 'bore': 875,\n"," 'spade': 876,\n"," 'gallowes': 877,\n"," 'sings': 878,\n"," 'rites': 879,\n"," \"woo't\": 880,\n"," 'cup': 881,\n"," 'vnfold': 882,\n"," 'bitter': 883,\n"," 'guard': 884,\n"," 'mouse': 885,\n"," \"appear'd\": 886,\n"," 'saies': 887,\n"," 'touching': 888,\n"," 'along': 889,\n"," 'appeare': 890,\n"," 'beating': 891,\n"," 'offended': 892,\n"," 'ambitious': 893,\n"," 'iust': 894,\n"," 'knowes': 895,\n"," 'subiect': 896,\n"," 'sore': 897,\n"," 'least': 898,\n"," 'valiant': 899,\n"," 'recouer': 900,\n"," 'termes': 901,\n"," 'maine': 902,\n"," 'loe': 903,\n"," 'offer': 904,\n"," 'present': 905,\n"," 'dew': 906,\n"," 'high': 907,\n"," 'hill': 908,\n"," 'aduice': 909,\n"," 'consent': 910,\n"," 'scena': 911,\n"," 'greene': 912,\n"," 'hearts': 913,\n"," 'wisest': 914,\n"," 'remembrance': 915,\n"," 'funerall': 916,\n"," 'delight': 917,\n"," 'affaire': 918,\n"," 'thinking': 919,\n"," 'voltemand': 920,\n"," 'vncle': 921,\n"," 'heartily': 922,\n"," 'bend': 923,\n"," 'bow': 924,\n"," 'cosin': 925,\n"," 'clouds': 926,\n"," 'sun': 927,\n"," 'liues': 928,\n"," 'passing': 929,\n"," 'formes': 930,\n"," 'vnderstanding': 931,\n"," 'sence': 932,\n"," 'coarse': 933,\n"," 'dyed': 934,\n"," 'beares': 935,\n"," 'wittenberg': 936,\n"," 'courtier': 937,\n"," 'louing': 938,\n"," 'smiling': 939,\n"," 'manet': 940,\n"," 'fixt': 941,\n"," 'flat': 942,\n"," 'vses': 943,\n"," 'married': 944,\n"," 'hercules': 945,\n"," 'salt': 946,\n"," 'change': 947,\n"," 'deepe': 948,\n"," 'mock': 949,\n"," 'hard': 950,\n"," 'tables': 951,\n"," 'goodly': 952,\n"," 'admiration': 953,\n"," 'deliuer': 954,\n"," 'cap': 955,\n"," 'appeares': 956,\n"," 'whilst': 957,\n"," 'dreadfull': 958,\n"," 'third': 959,\n"," 'sirs': 960,\n"," 'foote': 961,\n"," 'staid': 962,\n"," 'assume': 963,\n"," 'person': 964,\n"," 'mens': 965,\n"," 'choyce': 966,\n"," 'beauty': 967,\n"," 'spring': 968,\n"," 'aboord': 969,\n"," 'saile': 970,\n"," 'few': 971,\n"," 'steele': 972,\n"," 'entertainment': 973,\n"," 'censure': 974,\n"," 'rich': 975,\n"," 'generous': 976,\n"," 'edge': 977,\n"," 'tenders': 978,\n"," 'pay': 979,\n"," 'tender': 980,\n"," 'honourable': 981,\n"," 'presence': 982,\n"," 'meere': 983,\n"," 'wayes': 984,\n"," 'hower': 985,\n"," 'strooke': 986,\n"," 'wont': 987,\n"," \"honour'd\": 988,\n"," 'angels': 989,\n"," 'royall': 990,\n"," 'burst': 991,\n"," 'ignorance': 992,\n"," 'shake': 993,\n"," 'wherefore': 994,\n"," 'tempt': 995,\n"," 'lets': 996,\n"," 'lead': 997,\n"," 'crimes': 998,\n"," 'starres': 999,\n"," 'stirre': 1000,\n"," ...}"]},"metadata":{},"execution_count":3}],"source":["total_words\n","# how tokenize in entair data set\n","tokenizer.word_index"]},{"cell_type":"code","execution_count":4,"id":"9a61a891","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9a61a891","executionInfo":{"status":"ok","timestamp":1759589556477,"user_tz":-360,"elapsed":73,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"bd861c48-99d9-48cf-966c-c57b2aa4e59c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total input sequences: 25732\n"]}],"source":["# Step 1: Initialize a list to store input sequences\n","input_sequences = []  # This list will hold sequences of words for training\n","\n","# Step 2: Loop through each line of the text\n","for line in text.split('\\n'):  # Split text by newline to process line by line\n","    # Step 3: Convert the line into a sequence of word indices\n","    token_list = tokenizer.texts_to_sequences([line])[0]  # texts_to_sequences returns a list, take the first element\n","\n","    # Step 4: Create n-gram sequences from the token list\n","    for i in range(1, len(token_list)):\n","        # Take tokens from start to i+1 to form an n-gram\n","        n_gram_sequence = token_list[:i+1]\n","\n","        # Step 5: Append the sequence to the input_sequences list\n","        input_sequences.append(n_gram_sequence)\n","\n","# Step 6: Check how many sequences were created\n","print(f'Total input sequences: {len(input_sequences)}')\n"]},{"cell_type":"markdown","id":"b2f3b93c","metadata":{"id":"b2f3b93c"},"source":["\n","Input Sequences: Teaches the model the relationship between a context and the next word.\n","\n","Sentence: \"to be or not to be\"\n","Tokens: [5, 12, 3, 7, 5, 12]\n","Generated Sequences:\n","[5, 12] -> Target: 3\n","[5, 12, 3] -> Target: 7\n","[5, 12, 3, 7] -> Target: 5\n","[5, 12, 3, 7, 5] -> Target: 12"]},{"cell_type":"code","execution_count":5,"id":"5ed1499a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ed1499a","executionInfo":{"status":"ok","timestamp":1759589556611,"user_tz":-360,"elapsed":123,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"1e0d8967-20fc-4a91-a87c-6e2f697f0d0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum sequence length: 14\n"]}],"source":["# Step 1: Find the maximum sequence length\n","max_sequence_len = max([len(x) for x in input_sequences])\n","# This is needed because LSTM models expect all input sequences to have the same length\n","print(f\"Maximum sequence length: {max_sequence_len}\")"]},{"cell_type":"markdown","id":"a55805f0","metadata":{"id":"a55805f0"},"source":["### **Why padding is  needed?**\n","\n","**LSTM Requires Fixed-Length Input:**\n","- LSTM or RNN models require input sequences to be of the same length.\n","- However, the n-gram sequences we created have different lengths.\n","\n","**Padding Solves the Problem:**\n","- We add zeros at the beginning of shorter sequences to make their length equal to `max_sequence_len`.\n","\n","**Example:**\n","- Original sequence: `[5, 12, 3]`\n","- Max length = 6\n","- After padding: `[0, 0, 0, 5, 12, 3]`\n","\n","**The Model Understands:**\n","- The model learns to ignore the zero padding and focuses on learning to predict the next word from the proper context."]},{"cell_type":"code","execution_count":6,"id":"70536b22","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70536b22","executionInfo":{"status":"ok","timestamp":1759589556641,"user_tz":-360,"elapsed":29,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"0633af79-04a7-4a6e-ce11-a4619a5cba72"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[   0    0    0    0    0    0    0    0    0    0    0    0    1  687]\n"," [   0    0    0    0    0    0    0    0    0    0    0    1  687    4]\n"," [   0    0    0    0    0    0    0    0    0    0    1  687    4   45]\n"," [   0    0    0    0    0    0    0    0    0    1  687    4   45   41]\n"," [   0    0    0    0    0    0    0    0    1  687    4   45   41 1886]]\n"]}],"source":["# Step 1: Import pad_sequences (already imported earlier)\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Step 2: Pad all input sequences to have the same length\n","input_sequences = np.array(pad_sequences(input_sequences,\n","                                        maxlen=max_sequence_len,  # Pad all sequences to max length\n","                                        padding='pre'))           # Add padding at the beginning\n","\n","# Step 3: Check the padded sequences\n","print(input_sequences[:5])  # Display first 5 sequences to see padding\n"]},{"cell_type":"code","execution_count":7,"id":"b5a8488f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b5a8488f","executionInfo":{"status":"ok","timestamp":1759589556852,"user_tz":-360,"elapsed":125,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"26cd779f-fd31-4856-8cb4-5c9611066030"},"outputs":[{"output_type":"stream","name":"stdout","text":["X shape: (25732, 13)\n","y shape: (25732,)\n"]}],"source":["# Step 1: Import TensorFlow (already imported)\n","import tensorflow as tf\n","\n","# Step 2: Split input_sequences into predictors (X) and label (y)\n","x = input_sequences[:, :-1]  # All words except the last one are inputs (predictors)\n","y = input_sequences[:, -1]   # The last word in each sequence is the target (label)\n","\n","# Step 3: Check shapes\n","print(f'X shape: {x.shape}')\n","print(f'y shape: {y.shape}')\n"]},{"cell_type":"markdown","id":"06297dc9","metadata":{"id":"06297dc9"},"source":["### **Why is this step needed?**\n","\n","**Predictors (X):**\n","- The model learns to predict the next word from these sequences.\n","- Example: `[0, 0, 0, 5, 12]` → The model will predict the next word based on this context.\n","\n","**Label (y):**\n","- This is the target word that the model needs to predict.\n","- Example: From the sequence `[0, 0, 0, 5, 12, 3]`, the number `3` will be the target.\n","\n","**Training-ready format:**\n","- Now we can one-hot encode `y` because the LSTM output will be categorical (with vocabulary size number of classes).\n","- This creates the final format needed for training the neural network."]},{"cell_type":"code","execution_count":8,"id":"27e26dea","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"27e26dea","executionInfo":{"status":"ok","timestamp":1759589556859,"user_tz":-360,"elapsed":5,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"bd877e29-e065-46fc-82f2-85ca832c8cf8"},"outputs":[{"output_type":"stream","name":"stdout","text":["One-hot encoded y shape: (25732, 4818)\n"]}],"source":["# Step 1: One-hot encode the target labels\n","y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n","# Converts each integer label into a vector of length = total_words\n","# Example: if total_words = 100, label 5 → [0,0,0,0,0,1,0,...,0]\n","\n","# Step 2: Check the shape of y\n","print(f'One-hot encoded y shape: {y.shape}')\n"]},{"cell_type":"markdown","id":"2c8aca9f","metadata":{"id":"2c8aca9f"},"source":["# Split the data into training and testing sets"]},{"cell_type":"code","execution_count":9,"id":"d1a9f2af","metadata":{"id":"d1a9f2af","executionInfo":{"status":"ok","timestamp":1759589557248,"user_tz":-360,"elapsed":387,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}}},"outputs":[],"source":["# Split the data into training and testing sets\n","x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"]},{"cell_type":"markdown","source":["Model Trinig"],"metadata":{"id":"Lp2CqdWSd2l_"},"id":"Lp2CqdWSd2l_"},{"cell_type":"code","execution_count":10,"id":"a3a9d810","metadata":{"id":"a3a9d810","executionInfo":{"status":"ok","timestamp":1759589557272,"user_tz":-360,"elapsed":21,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}}},"outputs":[],"source":["# Step 1: Import EarlyStopping callback from Keras\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Step 2: Define EarlyStopping\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',        # Monitor the validation loss during training\n","    patience=3,                # Stop training if val_loss doesn't improve for 3 consecutive epochs\n","    restore_best_weights=True  # After stopping, restore model weights from the epoch with the best val_loss\n",")\n","\n","# Step 3: Why we use it?\n","# - Prevents overfitting by stopping training early\n","# - Saves time by not training unnecessary epochs\n","# - Ensures the model keeps the best weights observed during training\n"]},{"cell_type":"code","execution_count":11,"id":"389c2a31","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":344},"id":"389c2a31","executionInfo":{"status":"ok","timestamp":1759589557537,"user_tz":-360,"elapsed":266,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"a09bbe7f-fb4c-4165-f974-66131b509073"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m481,800\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │       \u001b[38;5;34m150,600\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m100,400\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4818\u001b[0m)           │       \u001b[38;5;34m486,618\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">481,800</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,400</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4818</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">486,618</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,219,418\u001b[0m (4.65 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,219,418</span> (4.65 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,219,418\u001b[0m (4.65 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,219,418</span> (4.65 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}],"source":["# Step 1: Import necessary layers and model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n","\n","# Step 2: Define the Sequential model\n","model = Sequential()\n","\n","# Step 3: Add Embedding layer\n","model.add(Embedding(\n","    input_dim=total_words,     # Vocabulary size\n","    output_dim=100,            # Embedding vector size\n","    input_length=max_sequence_len-1  # Input sequence length (excluding target word)\n","))\n","# Embedding layer converts word indices into dense vectors\n","\n","# Step 4: Add first LSTM layer\n","model.add(LSTM(150, return_sequences=True))\n","# return_sequences=True because we will stack another LSTM on top\n","\n","# Step 5: Add Dropout layer to prevent overfitting\n","model.add(Dropout(0.2))\n","\n","# Step 6: Add second LSTM layer\n","model.add(LSTM(100))\n","# return_sequences=False by default, outputs the last hidden state\n","\n","# Step 7: Add Dense output layer with softmax activation\n","model.add(Dense(total_words, activation=\"softmax\"))\n","# Predicts probability for each word in the vocabulary\n","\n","# Step 8: Compile the model\n","model.compile(\n","    loss=\"categorical_crossentropy\",  # Suitable for multi-class classification\n","    optimizer='adam',                 # Adam optimizer for faster convergence\n","    metrics=['accuracy']              # Track accuracy during training\n",")\n","\n","# Explicitly build the model with the input shape\n","model.build(input_shape=(None, max_sequence_len - 1))\n","\n","\n","# Step 9: Show model summary\n","model.summary()"]},{"cell_type":"code","execution_count":12,"id":"4bb28d6b","metadata":{"id":"4bb28d6b","executionInfo":{"status":"ok","timestamp":1759589557557,"user_tz":-360,"elapsed":17,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}}},"outputs":[],"source":["# ## GRU RNN\n","# ## Define the model\n","# model=Sequential()\n","# model.add(Embedding(total_words,100,input_length=max_sequence_len-1))\n","# model.add(GRU(150,return_sequences=True))\n","# model.add(Dropout(0.2))\n","# model.add(GRU(100))\n","# model.add(Dense(total_words,activation=\"softmax\"))\n","\n","# # #Compile the model\n","# model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])\n","# model.build(input_shape=(None, max_sequence_len-1))\n","# model.summary()"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9192c4f","outputId":"5c8b3be5-979d-4ea6-b7a6-faa3dcb07ee1","executionInfo":{"status":"ok","timestamp":1759591420829,"user_tz":-360,"elapsed":1863248,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}}},"source":["history=model.fit(x_train,y_train,epochs=50,validation_data=(x_test,y_test),verbose=1)"],"id":"d9192c4f","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 59ms/step - accuracy: 0.0297 - loss: 7.1236 - val_accuracy: 0.0336 - val_loss: 6.7409\n","Epoch 2/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 57ms/step - accuracy: 0.0362 - loss: 6.4470 - val_accuracy: 0.0418 - val_loss: 6.8087\n","Epoch 3/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 54ms/step - accuracy: 0.0439 - loss: 6.3226 - val_accuracy: 0.0484 - val_loss: 6.8297\n","Epoch 4/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 54ms/step - accuracy: 0.0515 - loss: 6.1552 - val_accuracy: 0.0464 - val_loss: 6.8436\n","Epoch 5/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 56ms/step - accuracy: 0.0561 - loss: 6.0192 - val_accuracy: 0.0507 - val_loss: 6.8764\n","Epoch 6/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 61ms/step - accuracy: 0.0616 - loss: 5.8769 - val_accuracy: 0.0554 - val_loss: 6.9746\n","Epoch 7/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 55ms/step - accuracy: 0.0700 - loss: 5.7608 - val_accuracy: 0.0618 - val_loss: 6.9991\n","Epoch 8/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 56ms/step - accuracy: 0.0747 - loss: 5.6113 - val_accuracy: 0.0643 - val_loss: 7.0246\n","Epoch 9/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 56ms/step - accuracy: 0.0871 - loss: 5.4381 - val_accuracy: 0.0682 - val_loss: 7.1199\n","Epoch 10/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 56ms/step - accuracy: 0.1006 - loss: 5.2791 - val_accuracy: 0.0680 - val_loss: 7.2057\n","Epoch 11/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 55ms/step - accuracy: 0.1086 - loss: 5.1401 - val_accuracy: 0.0686 - val_loss: 7.3432\n","Epoch 12/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 57ms/step - accuracy: 0.1130 - loss: 4.9965 - val_accuracy: 0.0657 - val_loss: 7.4546\n","Epoch 13/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 54ms/step - accuracy: 0.1159 - loss: 4.9007 - val_accuracy: 0.0690 - val_loss: 7.5926\n","Epoch 14/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 55ms/step - accuracy: 0.1236 - loss: 4.7423 - val_accuracy: 0.0661 - val_loss: 7.7066\n","Epoch 15/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 55ms/step - accuracy: 0.1260 - loss: 4.6353 - val_accuracy: 0.0653 - val_loss: 7.8297\n","Epoch 16/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 54ms/step - accuracy: 0.1382 - loss: 4.5037 - val_accuracy: 0.0641 - val_loss: 7.9797\n","Epoch 17/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 55ms/step - accuracy: 0.1461 - loss: 4.3709 - val_accuracy: 0.0622 - val_loss: 8.1086\n","Epoch 18/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 55ms/step - accuracy: 0.1484 - loss: 4.2870 - val_accuracy: 0.0624 - val_loss: 8.2607\n","Epoch 19/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 56ms/step - accuracy: 0.1648 - loss: 4.1863 - val_accuracy: 0.0600 - val_loss: 8.4035\n","Epoch 20/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 55ms/step - accuracy: 0.1778 - loss: 4.0792 - val_accuracy: 0.0614 - val_loss: 8.5634\n","Epoch 21/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 60ms/step - accuracy: 0.1906 - loss: 3.9809 - val_accuracy: 0.0620 - val_loss: 8.6995\n","Epoch 22/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 56ms/step - accuracy: 0.2091 - loss: 3.8695 - val_accuracy: 0.0589 - val_loss: 8.8076\n","Epoch 23/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 55ms/step - accuracy: 0.2234 - loss: 3.7841 - val_accuracy: 0.0596 - val_loss: 8.9591\n","Epoch 24/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 59ms/step - accuracy: 0.2367 - loss: 3.6977 - val_accuracy: 0.0624 - val_loss: 9.1093\n","Epoch 25/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 55ms/step - accuracy: 0.2526 - loss: 3.6377 - val_accuracy: 0.0604 - val_loss: 9.2287\n","Epoch 26/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 55ms/step - accuracy: 0.2646 - loss: 3.5580 - val_accuracy: 0.0618 - val_loss: 9.3377\n","Epoch 27/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 55ms/step - accuracy: 0.2757 - loss: 3.4866 - val_accuracy: 0.0558 - val_loss: 9.4535\n","Epoch 28/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 55ms/step - accuracy: 0.2865 - loss: 3.4212 - val_accuracy: 0.0602 - val_loss: 9.5591\n","Epoch 29/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 56ms/step - accuracy: 0.2984 - loss: 3.3602 - val_accuracy: 0.0575 - val_loss: 9.6793\n","Epoch 30/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 57ms/step - accuracy: 0.3107 - loss: 3.2940 - val_accuracy: 0.0560 - val_loss: 9.8152\n","Epoch 31/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 56ms/step - accuracy: 0.3176 - loss: 3.2224 - val_accuracy: 0.0571 - val_loss: 9.9064\n","Epoch 32/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 56ms/step - accuracy: 0.3241 - loss: 3.1743 - val_accuracy: 0.0544 - val_loss: 10.0058\n","Epoch 33/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 56ms/step - accuracy: 0.3393 - loss: 3.1254 - val_accuracy: 0.0583 - val_loss: 10.0964\n","Epoch 34/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 56ms/step - accuracy: 0.3449 - loss: 3.0759 - val_accuracy: 0.0556 - val_loss: 10.1568\n","Epoch 35/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 56ms/step - accuracy: 0.3560 - loss: 3.0284 - val_accuracy: 0.0581 - val_loss: 10.2791\n","Epoch 36/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 58ms/step - accuracy: 0.3677 - loss: 2.9567 - val_accuracy: 0.0563 - val_loss: 10.3780\n","Epoch 37/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 56ms/step - accuracy: 0.3818 - loss: 2.9014 - val_accuracy: 0.0567 - val_loss: 10.4720\n","Epoch 38/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 56ms/step - accuracy: 0.3779 - loss: 2.8928 - val_accuracy: 0.0548 - val_loss: 10.5621\n","Epoch 39/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 55ms/step - accuracy: 0.3895 - loss: 2.8367 - val_accuracy: 0.0567 - val_loss: 10.6487\n","Epoch 40/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 54ms/step - accuracy: 0.3932 - loss: 2.8077 - val_accuracy: 0.0544 - val_loss: 10.7341\n","Epoch 41/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 55ms/step - accuracy: 0.4142 - loss: 2.7351 - val_accuracy: 0.0565 - val_loss: 10.8031\n","Epoch 42/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 57ms/step - accuracy: 0.4180 - loss: 2.6941 - val_accuracy: 0.0558 - val_loss: 10.8734\n","Epoch 43/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 55ms/step - accuracy: 0.4208 - loss: 2.6631 - val_accuracy: 0.0561 - val_loss: 10.9574\n","Epoch 44/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 56ms/step - accuracy: 0.4282 - loss: 2.6393 - val_accuracy: 0.0571 - val_loss: 11.0313\n","Epoch 45/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 54ms/step - accuracy: 0.4415 - loss: 2.5823 - val_accuracy: 0.0577 - val_loss: 11.1142\n","Epoch 46/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 56ms/step - accuracy: 0.4448 - loss: 2.5562 - val_accuracy: 0.0554 - val_loss: 11.2231\n","Epoch 47/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 55ms/step - accuracy: 0.4470 - loss: 2.5174 - val_accuracy: 0.0571 - val_loss: 11.2837\n","Epoch 48/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 57ms/step - accuracy: 0.4603 - loss: 2.4767 - val_accuracy: 0.0581 - val_loss: 11.3829\n","Epoch 49/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 55ms/step - accuracy: 0.4674 - loss: 2.4497 - val_accuracy: 0.0569 - val_loss: 11.4538\n","Epoch 50/50\n","\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 54ms/step - accuracy: 0.4698 - loss: 2.4239 - val_accuracy: 0.0554 - val_loss: 11.5486\n"]}]},{"cell_type":"code","execution_count":14,"id":"8c74504b","metadata":{"id":"8c74504b","executionInfo":{"status":"ok","timestamp":1759591420833,"user_tz":-360,"elapsed":2,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}}},"outputs":[],"source":["# Function to predict the next word\n","def predict_next_word(model, tokenizer, text, max_sequence_len):\n","    token_list = tokenizer.texts_to_sequences([text])[0]\n","    if len(token_list) >= max_sequence_len:\n","        token_list = token_list[-(max_sequence_len-1):]  # Ensure the sequence length matches max_sequence_len-1\n","    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","    predicted = model.predict(token_list, verbose=0)\n","    predicted_word_index = np.argmax(predicted, axis=1)\n","    for word, index in tokenizer.word_index.items():\n","        if index == predicted_word_index:\n","            return word\n","    return None"]},{"cell_type":"code","execution_count":15,"id":"d5118ca7","metadata":{"id":"d5118ca7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759591421442,"user_tz":-360,"elapsed":607,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"df370e9e-a2ae-4ab2-8cdf-c801593eac46"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input text:I love AI \n","Next Word PRediction:haue\n"]}],"source":["input_text=\"I love AI \"\n","print(f\"Input text:{input_text}\")\n","max_sequence_len=model.input_shape[1]+1\n","next_word=predict_next_word(model,tokenizer,input_text,max_sequence_len)\n","print(f\"Next Word PRediction:{next_word}\")"]},{"cell_type":"code","execution_count":16,"id":"a5123f4b","metadata":{"id":"a5123f4b","executionInfo":{"status":"ok","timestamp":1759591421445,"user_tz":-360,"elapsed":1,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}}},"outputs":[],"source":["## Save the model\n","model.save(\"next_word_lstm.keras\")\n","## Save the tokenizer\n","import pickle\n","with open('tokenizer.pickle','wb') as handle:\n","    pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)"]},{"cell_type":"code","execution_count":17,"id":"63764883","metadata":{"id":"63764883","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759591421648,"user_tz":-360,"elapsed":201,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"a06b53f0-2029-4c80-cc7a-393b61579d25"},"outputs":[{"output_type":"stream","name":"stdout","text":["Input text:  Barn. Last night of all,When yond same\n","Next Word PRediction:scull\n"]}],"source":["input_text=\"  Barn. Last night of all,When yond same\"\n","print(f\"Input text:{input_text}\")\n","max_sequence_len=model.input_shape[1]+1\n","next_word=predict_next_word(model,tokenizer,input_text,max_sequence_len)\n","print(f\"Next Word PRediction:{next_word}\")"]},{"cell_type":"code","source":["# Folder Create and download model"],"metadata":{"id":"FTevBJ24uBTq","executionInfo":{"status":"ok","timestamp":1759591421660,"user_tz":-360,"elapsed":6,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}}},"id":"FTevBJ24uBTq","execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"d34a956a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759591421683,"user_tz":-360,"elapsed":17,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"fc9648eb-e717-4829-ce63-229ee74acc4a"},"source":["import os\n","print(os.listdir('.'))"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["['.config', 'next_word_lstm.keras', 'tokenizer.pickle', 'hamlet.txt', 'sample_data']\n"]}],"id":"d34a956a"},{"cell_type":"code","metadata":{"id":"75b0ece7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759591421694,"user_tz":-360,"elapsed":8,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"12053140-9bf8-46af-ebea-f2234cd21701"},"source":["import zipfile\n","\n","# List of files to include\n","files_to_zip = ['next_word_lstm.keras', 'tokenizer.pickle']\n","zip_filename = 'next_word_prediction_model.zip'\n","\n","# Create a zip archive\n","with zipfile.ZipFile(zip_filename, 'w') as zipf:\n","    for file in files_to_zip:\n","        zipf.write(file)  # Add file to zip\n","\n","print(f\"Created {zip_filename} containing the model and tokenizer.\")\n"],"id":"75b0ece7","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Created next_word_prediction_model.zip containing the model and tokenizer.\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download(zip_filename)\n"],"metadata":{"id":"mYW9edPFwrmE","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1759591421700,"user_tz":-360,"elapsed":5,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"f0ccd529-18d8-4cab-d4ab-6a2efa1acd34"},"id":"mYW9edPFwrmE","execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_73befc10-532f-47a2-8f9e-f20ed5ab0531\", \"next_word_prediction_model.zip\", 14859437)"]},"metadata":{}}]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import pickle\n","\n","# Load the trained model\n","model = tf.keras.models.load_model('next_word_lstm.keras')\n","\n","# Load the tokenizer\n","with open('tokenizer.pickle', 'rb') as handle:\n","    tokenizer = pickle.load(handle)\n","\n","max_sequence_len = model.input_shape[1] + 1\n","\n","# Function to predict the next word\n","def predict_next_word(model, tokenizer, text, max_sequence_len):\n","    token_list = tokenizer.texts_to_sequences([text])[0]\n","    if len(token_list) >= max_sequence_len:\n","        token_list = token_list[-(max_sequence_len-1):]\n","    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","    predicted = model.predict(token_list, verbose=0)\n","    predicted_word_index = np.argmax(predicted, axis=1)\n","    for word, index in tokenizer.word_index.items():\n","        if index == predicted_word_word_index:\n","            return word\n","    return None\n","\n","# Streamlit app\n","st.title(\"Next Word Prediction using LSTM\")\n","\n","input_text = st.text_input(\"Enter a sentence:\")\n","\n","if input_text:\n","    next_word = predict_next_word(model, tokenizer, input_text, max_sequence_len)\n","    if next_word:\n","        st.write(f\"Next word prediction: **{next_word}**\")\n","    else:\n","        st.write(\"Could not predict the next word.\")"],"metadata":{"id":"8WH-_gUbwroI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759591421709,"user_tz":-360,"elapsed":7,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"b1c92bc8-bf7b-44e2-fa70-d9b06b9017ca"},"id":"8WH-_gUbwroI","execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing app.py\n"]}]},{"cell_type":"code","source":["!pip install streamlit\n","!streamlit run app.py &>/dev/null&"],"metadata":{"id":"wZO2CHf5wrqo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759591432950,"user_tz":-360,"elapsed":11239,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"1a3b2ad6-1c8a-446c-aa1d-e9754941733c"},"id":"wZO2CHf5wrqo","execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting streamlit\n","  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n","Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.6.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n","Downloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pydeck, streamlit\n","Successfully installed pydeck-0.9.1 streamlit-1.50.0\n"]}]},{"cell_type":"code","source":["import pkg_resources\n","\n","# Define a list of the packages used in the notebook\n","packages = ['nltk', 'pandas', 'numpy', 'tensorflow', 'sklearn', 'streamlit', 'pickle']\n","\n","# Print the version of each package if it's installed\n","for package in packages:\n","    try:\n","        print(f\"{package}: {pkg_resources.get_distribution(package).version}\")\n","    except pkg_resources.DistributionNotFound:\n","        print(f\"{package}: Not installed\")"],"metadata":{"id":"TY1ULPKAHFBf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759591433875,"user_tz":-360,"elapsed":923,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"4b3b1048-3a89-4c05-d5c7-7418091b272c"},"id":"TY1ULPKAHFBf","execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1104353115.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n","  import pkg_resources\n"]},{"output_type":"stream","name":"stdout","text":["nltk: 3.9.1\n","pandas: 2.2.2\n","numpy: 2.0.2\n","tensorflow: 2.19.0\n","sklearn: Not installed\n","streamlit: 1.50.0\n","pickle: Not installed\n"]}]},{"cell_type":"code","metadata":{"id":"ae7f4424","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759591452228,"user_tz":-360,"elapsed":18351,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"c442f803-bd29-4bf4-aea8-d71cfbdaee7c"},"source":["!pip install scikit-learn streamlit pickle5"],"id":"ae7f4424","execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.50.0)\n","Collecting pickle5\n","  Downloading pickle5-0.0.11.tar.gz (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n","Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.6.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n","Building wheels for collected packages: pickle5\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for pickle5 (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for pickle5\u001b[0m\u001b[31m\n","\u001b[0m\u001b[?25h  Running setup.py clean for pickle5\n","Failed to build pickle5\n","\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pickle5)\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","metadata":{"id":"ac1084fd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759591452240,"user_tz":-360,"elapsed":8,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"63e9cd0f-32d4-40fe-fd2f-bf9ea051d988"},"source":["import pkg_resources\n","\n","# Define a list of the packages used in the notebook\n","packages = ['nltk', 'pandas', 'numpy', 'tensorflow', 'sklearn', 'streamlit', 'pickle']\n","\n","# Print the version of each package if it's installed\n","for package in packages:\n","    try:\n","        print(f\"{package}: {pkg_resources.get_distribution(package).version}\")\n","    except pkg_resources.DistributionNotFound:\n","        print(f\"{package}: Not installed\")"],"id":"ac1084fd","execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["nltk: 3.9.1\n","pandas: 2.2.2\n","numpy: 2.0.2\n","tensorflow: 2.19.0\n","sklearn: Not installed\n","streamlit: 1.50.0\n","pickle: Not installed\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","print(tf.__version__)\n"],"metadata":{"id":"5DTXSZL2L5AB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759591452250,"user_tz":-360,"elapsed":8,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}},"outputId":"7b061300-d604-4d52-c794-a89a32248909"},"id":"5DTXSZL2L5AB","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["2.19.0\n"]}]},{"cell_type":"code","source":["!pip freeze > requirements.txt\n"],"metadata":{"id":"ele5MIRLL5CD","executionInfo":{"status":"ok","timestamp":1759591455507,"user_tz":-360,"elapsed":3255,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}}},"id":"ele5MIRLL5CD","execution_count":28,"outputs":[]},{"cell_type":"code","source":["# tokenizer JSON format save\n","tokenizer_json = tokenizer.to_json()\n","with open(\"tokenizer.json\", \"w\", encoding=\"utf-8\") as f:\n","    f.write(tokenizer_json)\n"],"metadata":{"id":"oXfiAg1aL5Ey","executionInfo":{"status":"ok","timestamp":1759591455525,"user_tz":-360,"elapsed":6,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}}},"id":"oXfiAg1aL5Ey","execution_count":29,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"78HUKNKMq4Hf","executionInfo":{"status":"ok","timestamp":1759591455537,"user_tz":-360,"elapsed":6,"user":{"displayName":"Asux Ai","userId":"06559001413637975182"}}},"id":"78HUKNKMq4Hf","execution_count":29,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"skill_dev","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.18"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}